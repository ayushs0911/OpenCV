{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNDfGS8J1NRUUGBYotmzlAU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayushs0911/OpenCV/blob/main/Haar_Cascade_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvMKkgagJdCT"
      },
      "outputs": [],
      "source": [
        "# Our Setup, Import Libaries, Create our Imshow Function and Download our Images\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Define our imshow function \n",
        "def imshow(title = \"Image\", image = None, size = 10):\n",
        "    w, h = image.shape[0], image.shape[1]\n",
        "    aspect_ratio = w/h\n",
        "    plt.figure(figsize=(size * aspect_ratio,size))\n",
        "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "# Download and unzip our images and Haarcascade Classifiers\n",
        "!wget https://moderncomputervision.s3.eu-west-2.amazonaws.com/images.zip\n",
        "!wget https://moderncomputervision.s3.eu-west-2.amazonaws.com/haarcascades.zip\n",
        "\n",
        "!unzip -qq images.zip\n",
        "!unzip -qq haarcascades.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **HAAR Cascade Classifiers**\n",
        "\n",
        "Developed by Viola and Jones in 2001.\n",
        "\n",
        "An object detection method that uses a series of classifiers (cascade) to identify objects in an image. They are trained to identify one type of object, however, we can use several of them in parallel e.g. detecting eyes and faces together. HAAR Classifiers are trained using lots of positive images (i.e. images with the object present) and negative images (i.e. images without the object present).\n",
        "![](https://github.com/rajeevratan84/ModernComputerVision/raw/main/haar.png)\n",
        "\n",
        "\n",
        "The Haar cascade classifier is an object detection algorithm used for identifying objects or specific features within images or video frames. It is particularly known for its effectiveness in detecting faces, although it can be trained to detect other objects as well.\n",
        "\n",
        "The algorithm is based on Haar-like features, which are simple rectangular filters that are applied to different regions of an image. These features are computed by calculating the difference between the sum of pixel intensities in the white and black rectangles within the region of interest. By evaluating a large number of these features at various scales and positions, the Haar cascade classifier can effectively differentiate between the object of interest and the background.\n",
        "\n",
        "The Haar cascade classifier employs a cascade of classifiers, which is a sequence of stages where each stage consists of multiple weak classifiers. These weak classifiers are simple classifiers, such as decision trees or linear classifiers, that are combined to form a strong classifier capable of making accurate detections. The cascade structure allows for fast and efficient object detection by quickly rejecting regions that are unlikely to contain the object, thus reducing the computational load.\n",
        "\n",
        "The training of a Haar cascade classifier involves a two-step process: positive sample collection and negative sample collection. Positive samples are images containing the object of interest, while negative samples are images without the object. The algorithm is trained using a machine learning technique called AdaBoost (Adaptive Boosting), which iteratively combines weak classifiers and adjusts their weights to improve overall detection performance.\n",
        "\n",
        "Once the Haar cascade classifier is trained, it can be used to detect the object in new images or video frames. The classifier slides a detection window across the image at different scales and positions, applying the learned cascade of classifiers to determine if the object is present. If a detection threshold is exceeded, the object is considered to be present in that region.\n",
        "\n",
        "While Haar cascade classifiers have been widely used and have shown good performance for certain object detection tasks, they have some limitations. They may struggle with detecting objects under variations in lighting conditions, scale, orientation, or occlusion. Additionally, they may produce false positives or false negatives depending on the quality of training data and the chosen detection thresholds.\n",
        "\n",
        "More advanced object detection techniques, such as deep learning-based approaches (e.g., convolutional neural networks), have gained popularity due to their superior performance on a wide range of object detection tasks. Nonetheless, Haar cascade classifiers remain relevant and can be a lightweight option for certain applications or scenarios with specific requirements."
      ],
      "metadata": {
        "id": "1hST4hZNK60-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#point opencv's Cascade classifier function to where our classifier is stored \n",
        "face_classifier = cv2.CascadeClassifier(\"/content/Haarcascades/haarcascade_frontalface_default.xml\")\n",
        "\n",
        "# load image and convert to grayscale \n",
        "image = cv2.imread('./images/Trump.jpg')\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "\n",
        "#classifier returns the ROI of the detected face as a tuple \n",
        "# it stores the top left coordinate and the bottom right coordinates \n",
        "faces = face_classifier.detectMultiScale(gray, scaleFactor = 1.3, minNeighbors = 5)\n",
        "\n",
        "#when no face detected, face_classifier returns empty tuple \n",
        "if faces is ():\n",
        "  print(\"No faces found\")\n",
        "\n",
        "#we iterate through our faces array and draw a rectangle over each face in frame\n",
        "for (x, y, w, h) in faces:\n",
        "  cv2.rectangle(image, (x,y), (x+w, y+h), (127, 0, 255), 2)\n",
        "\n",
        "imshow('Face detection', image)"
      ],
      "metadata": {
        "id": "iTZykbeJKr57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Simple Eye & Face Detection using Haarcascade Classifiers**"
      ],
      "metadata": {
        "id": "FmVkdTkecsR1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        " \n",
        "face_classifier = cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')\n",
        "eye_classifier = cv2.CascadeClassifier('Haarcascades/haarcascade_eye.xml')\n",
        " \n",
        "img = cv2.imread('images/Trump.jpg')\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
        "\n",
        "# When no faces detected, face_classifier returns and empty tuple\n",
        "if faces is ():\n",
        "    print(\"No Face Found\")\n",
        "\n",
        "for (x, y, w, h) in faces:\n",
        "  cv2.rectangle(img, (x,y), (x+w, y+h), (127,0,255),2)\n",
        "  roi_gray = gray[y:y+h, x:x+w]\n",
        "  roi_color = img[y:y+h, x:x+w]\n",
        "  eyes = eye_classifier.detectMultiScale(roi_gray, 1.2, 3)\n",
        "  for (ex, ey, ew, eh) in eyes:\n",
        "    cv2.rectangle(roi_color, (ex,ey), (ex+ew, ey+eh), (255,255,0), 2)\n",
        "\n",
        "imshow(\"Eye and Face detection\", img)\n"
      ],
      "metadata": {
        "id": "6dYgrgGnbXd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Using Colab's Code Snippets let's access the webcam for an input**\n",
        "\n",
        "Note: Requires your computer to have a webcam"
      ],
      "metadata": {
        "id": "bZKJKHcWhKWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "metadata": {
        "id": "WWpPhc6oc6Hh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "try:\n",
        "  filename = take_photo()\n",
        "  print('Saved to {}'.format(filename))\n",
        "  \n",
        "  # Show the image which was just taken.\n",
        "  display(Image(filename))\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))"
      ],
      "metadata": {
        "id": "NqZLygEphMJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        " \n",
        "face_classifier = cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')\n",
        "eye_classifier = cv2.CascadeClassifier('Haarcascades/haarcascade_eye.xml')\n",
        " \n",
        "img = cv2.imread('photo.jpg')\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
        "\n",
        "# When no faces detected, face_classifier returns and empty tuple\n",
        "if faces is ():\n",
        "    print(\"No Face Found\")\n",
        "\n",
        "for (x,y,w,h) in faces:\n",
        "    cv2.rectangle(img,(x,y),(x+w,y+h),(127,0,255),2)\n",
        "    roi_gray = gray[y:y+h, x:x+w]\n",
        "    roi_color = img[y:y+h, x:x+w]\n",
        "    eyes = eye_classifier.detectMultiScale(roi_gray)\n",
        "    for (ex,ey,ew,eh) in eyes:\n",
        "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(255,255,0),2)\n",
        "\n",
        "imshow('Eye & Face Detection',img)"
      ],
      "metadata": {
        "id": "n5BSCUNthPYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Bonus Code - Use your webcam to do live face and eye detection**\n",
        "\n",
        "This only works on a local machine, will not work in Colab"
      ],
      "metadata": {
        "id": "TNQM9VjShalt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "face_classifier = cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')\n",
        "eye_classifier = cv2.CascadeClassifier('Haarcascades/haarcascade_eye.xml')\n",
        "\n",
        "def face_detector(img, size=0.5):\n",
        "    # Convert image to grayscale\n",
        "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
        "    if faces is ():\n",
        "        return img\n",
        "    \n",
        "    for (x,y,w,h) in faces:\n",
        "        x = x - 50\n",
        "        w = w + 50\n",
        "        y = y - 50\n",
        "        h = h + 50\n",
        "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
        "        roi_gray = gray[y:y+h, x:x+w]\n",
        "        roi_color = img[y:y+h, x:x+w]\n",
        "        eyes = eye_classifier.detectMultiScale(roi_gray)\n",
        "        \n",
        "        for (ex,ey,ew,eh) in eyes:\n",
        "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,0,255),2) \n",
        "            \n",
        "    roi_color = cv2.flip(roi_color,1)\n",
        "    return roi_color\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "while True:\n",
        "\n",
        "    ret, frame = cap.read()\n",
        "    cv2.imshow('Our Face Extractor', face_detector(frame))\n",
        "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
        "        break\n",
        "        \n",
        "cap.release()\n",
        "cv2.destroyAllWindows()      "
      ],
      "metadata": {
        "id": "DLXNpTGAhWKg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}